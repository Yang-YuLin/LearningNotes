- 泛化性能评估方法 对数据集D分割产生训练集S和测试集T：
  - 留出法(hold-out)：将数据集D划分为两个互斥的集合：训练集S、测试集T。在S上训练出模型后，用T来评估其测试误差。
  - 交叉验证法(cross validation)：
  - 自助法(bootstrapping)：数据量少时用
  
- 性能度量：衡量模型泛化能力的评价标准
  - 回归任务：均方误差
  - 分类任务：
    - 错误率和精度
    - 查准率precision、查全率recall与F1度量
    - ROC与AUC(ROC曲线下的面积)
    - 代价敏感错误率与代价曲线
  
- 线性模型

  - 线性回归：基于最小化均方误差来进行模型求解，称为最小二乘法。 **回归任务**

    (在线性回归中，最小二乘法就是试图找到一条直线，使所有样本到直线上的欧式距离之和最小)

  - 对数几率回归：用线性回归模型的预测结果去逼近真实标记的对数几率  **分类任务**

  - 线性判别分析LDA：给定训练样例集，将样例投影到一条直线上，使得同类样例的投影点尽可能接近、异类样例的投影点尽可能远离。在对新样本进行分类时，将其投影到同样的这条直线上，再根据投影点的位置来确定新样本的类别。  **监督降维技术**

  - 多分类学习：将多分类任务拆为若干个二分类任务求解

    - 拆分策略：一对一OvO、一对其余OvR、多对多MvM

  - 类别不平衡问题：

    - 再缩放
    - 欠采样、过采样、阈值移动

- 决策树：基于树结构来进行决策的，从根节点一步步走到叶子节点(决策)  **分而治之**

  - 所有的数据最终都会落到叶子结点，既可以做分类也可以做回归
  - 划分选择：用**信息增益、增益率、基尼指数**来进行**决策树的划分属性选择**
  - 剪枝处理：降低过拟合    
    - “预剪枝”策略：分支更少，降低了过拟合；减少了训练和测试时间开销；易欠拟合
    - “后剪枝”策略：分支更多，欠拟合风险小，泛化性能高于预剪枝；时间开销大
  - 连续值处理：连续属性离散化技术     采用二分法对连续属性进行处理
    - 与离散属性不同，若当前结点划分属性为连续























